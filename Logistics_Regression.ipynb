{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Theoretical Answers**\n",
        "\n",
        "1. **What is Logistic Regression, and how does it differ from Linear Regression?**\n",
        "   - **Logistic Regression** is a statistical method used for binary classification problems, where the outcome is a binary value (e.g., 0 or 1). It estimates the probability of a binary response based on one or more predictor variables. In contrast, **Linear Regression** is used to predict continuous outcomes and models the relationship between a dependent variable and independent variables by fitting a linear equation to observed data.\n",
        "---\n",
        "2. **What is the mathematical equation of Logistic Regression?**\n",
        "   - The mathematical equation of Logistic Regression is:\n",
        "   \\[\n",
        "   P(Y=1 | X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_n X_n)}}\n",
        "   \\]\n",
        "   This is the logistic function (also called the Sigmoid function), where \\( \\beta_0 \\) is the intercept, \\( \\beta_1, \\beta_2, \\dots, \\beta_n \\) are the coefficients, and \\( X_1, X_2, \\dots, X_n \\) are the features.\n",
        "---\n",
        "3. **Why do we use the Sigmoid function in Logistic Regression?**\n",
        "   - The Sigmoid function maps any real-valued number into a range between 0 and 1, which is ideal for representing probabilities. This allows logistic regression to output probabilities that a given input belongs to a certain class (0 or 1).\n",
        "---\n",
        "4. **What is the cost function of Logistic Regression?**\n",
        "   - The cost function of Logistic Regression is the **log-loss** or **binary cross-entropy** function:\n",
        "   \\[\n",
        "   J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[y_i \\log(h_{\\theta}(x_i)) + (1 - y_i) \\log(1 - h_{\\theta}(x_i))\\right]\n",
        "   \\]\n",
        "   Where \\( h_{\\theta}(x_i) \\) is the predicted probability (using the Sigmoid function), and \\( y_i \\) is the actual label (0 or 1).\n",
        "---\n",
        "5. **What is Regularization in Logistic Regression? Why is it needed?**\n",
        "   - **Regularization** in Logistic Regression is used to prevent overfitting by adding a penalty term to the cost function. The two most common types are **L1 regularization (Lasso)** and **L2 regularization (Ridge)**. Regularization discourages overly complex models, encouraging simplicity and generalizability.\n",
        "---\n",
        "6. **Explain the difference between Lasso, Ridge, and Elastic Net regression.**\n",
        "   - **Lasso Regression (L1 Regularization)** adds a penalty equal to the absolute value of the coefficients. It can shrink some coefficients to zero, performing feature selection.\n",
        "   - **Ridge Regression (L2 Regularization)** adds a penalty equal to the square of the coefficients. It shrinks all coefficients, but none are exactly zero.\n",
        "   - **Elastic Net** is a combination of both L1 and L2 regularization, balancing between feature selection (Lasso) and coefficient shrinkage (Ridge).\n",
        "---\n",
        "7. **When should we use Elastic Net instead of Lasso or Ridge?**\n",
        "   - **Elastic Net** is preferred when there are many correlated features, as it can both shrink coefficients and select features, which might not be as effective with Lasso or Ridge alone.\n",
        "---\n",
        "8. **What is the impact of the regularization parameter (λ) in Logistic Regression?**\n",
        "   - The regularization parameter \\( \\lambda \\) controls the strength of the penalty. A larger value of \\( \\lambda \\) results in more regularization, leading to smaller coefficients (more regularization). A smaller \\( \\lambda \\) allows the model to fit more closely to the data, potentially leading to overfitting.\n",
        "---\n",
        "9. **What are the key assumptions of Logistic Regression?**\n",
        "   - Logistic regression assumes:\n",
        "     1. The dependent variable is binary (two classes).\n",
        "     2. The independent variables are linearly related to the log-odds of the dependent variable.\n",
        "     3. No multicollinearity (predictors should not be highly correlated).\n",
        "     4. Observations are independent.\n",
        "---\n",
        "10. **What are some alternatives to Logistic Regression for classification tasks?**\n",
        "    - Some alternatives include **Support Vector Machines (SVM)**, **Decision Trees**, **Random Forests**, **k-Nearest Neighbors (k-NN)**, **Naive Bayes**, and **Neural Networks**.\n",
        "---\n",
        "11. **What are Classification Evaluation Metrics?**\n",
        "    - Common classification evaluation metrics include:\n",
        "      1. **Accuracy**: Proportion of correct predictions.\n",
        "      2. **Precision**: Proportion of true positives among all positive predictions.\n",
        "      3. **Recall (Sensitivity)**: Proportion of true positives among all actual positives.\n",
        "      4. **F1 Score**: Harmonic mean of precision and recall.\n",
        "      5. **ROC Curve and AUC**: Measures the trade-off between true positive rate and false positive rate.\n",
        "---\n",
        "12. **How does class imbalance affect Logistic Regression?**\n",
        "    - **Class imbalance** can cause the model to be biased towards the majority class, resulting in poor performance on the minority class. It can be addressed by techniques such as oversampling, undersampling, or using appropriate evaluation metrics like precision-recall curves or AUC.\n",
        "---\n",
        "13. **What is Hyperparameter Tuning in Logistic Regression?**\n",
        "    - **Hyperparameter tuning** involves adjusting parameters like the regularization strength \\( \\lambda \\), solver type, and others to improve model performance. Techniques like **Grid Search** or **Random Search** can be used to find the best set of hyperparameters.\n",
        "---\n",
        "14. **What are different solvers in Logistic Regression? Which one should be used?**\n",
        "    - Common solvers for Logistic Regression include:\n",
        "      1. **‘liblinear’**: Good for small datasets, supports L1 regularization.\n",
        "      2. **‘newton-cg’**: Good for larger datasets, supports L2 regularization.\n",
        "      3. **‘lbfgs’**: Works well for multi-class classification.\n",
        "      4. **‘saga’**: Useful for large datasets, supports L1 and L2 regularization.\n",
        "    - The choice of solver depends on dataset size and the type of regularization needed.\n",
        "---\n",
        "15. **How is Logistic Regression extended for multiclass classification?**\n",
        "    - Logistic Regression can be extended for multiclass classification using **One-vs-Rest (OvR)** or **Softmax regression** (Multinomial Logistic Regression), where each class is modeled separately or by considering all classes simultaneously.\n",
        "---\n",
        "16. **What are the advantages and disadvantages of Logistic Regression?**\n",
        "    - **Advantages**:\n",
        "      1. Simple and interpretable.\n",
        "      2. Fast to train.\n",
        "      3. Works well for linearly separable data.\n",
        "    - **Disadvantages**:\n",
        "      1. Assumes a linear decision boundary.\n",
        "      2. Prone to underfitting with non-linear data.\n",
        "      3. Sensitive to feature scaling.\n",
        "---\n",
        "17. **What are some use cases of Logistic Regression?**\n",
        "    - Use cases include:\n",
        "      1. **Binary classification tasks** like spam detection, disease diagnosis, and fraud detection.\n",
        "      2. **Multiclass classification** with extensions like One-vs-Rest or Softmax.\n",
        "      3. Predicting probabilities, such as customer churn or loan defaults.\n",
        "---\n",
        "18. **What is the difference between Softmax Regression and Logistic Regression?**\n",
        "    - **Logistic Regression** is used for binary classification, while **Softmax Regression** (also called Multinomial Logistic Regression) is used for multiclass classification. Softmax generalizes the logistic function to handle multiple classes.\n",
        "---\n",
        "19. **How do we choose between One-vs-Rest (OVR) and Softmax for multiclass classification?**\n",
        "    - Use **One-vs-Rest (OVR)** when dealing with binary classifiers for each class, which may be more efficient for a large number of classes. Use **Softmax** when you want to model all classes simultaneously, and it generally performs better when the classes are not linearly separable.\n",
        "---\n",
        "20. **How do we interpret coefficients in Logistic Regression?**\n",
        "    - The **coefficients** in Logistic Regression represent the log-odds change of the dependent variable for a one-unit increase in the corresponding predictor variable. The exponential of the coefficient \\( e^{\\beta} \\) gives the **odds ratio**, which represents the change in the odds of the outcome for a one-unit change in the predictor.\n",
        "---    "
      ],
      "metadata": {
        "id": "1SiT0cCMZpuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Synthetic data generation\n",
        "np.random.seed(42)\n",
        "X = np.random.randn(100, 5)  # 100 rows, 5 features\n",
        "y = np.random.randint(0, 2, size=100)  # Binary target variable (0 or 1)\n",
        "\n",
        "# Create DataFrame\n",
        "data = pd.DataFrame(X, columns=[f'Feature_{i+1}' for i in range(X.shape[1])])\n",
        "data['Target'] = y\n",
        "\n",
        "# Save the data to a CSV file\n",
        "csv_file_path = '/content/synthetic_data.csv'\n",
        "data.to_csv(csv_file_path, index=False)\n",
        "\n",
        "# Provide download link\n",
        "from google.colab import files\n",
        "files.download(csv_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "sckyROvncwD0",
        "outputId": "e05ec252-6ab5-4dda-f3f4-4b01bff5bf96"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d605dc63-562d-4650-bfb1-012a8991becb\", \"synthetic_data.csv\", 10071)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 1: Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8v7Y4HVaC9K",
        "outputId": "14997f09-4078-45ab-e60c-fe50593727ac"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 2: Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression (penalty='l1') and print the model accuracy.\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Apply L1 regularization (Lasso)\n",
        "model_lasso = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "model_lasso.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_lasso = model_lasso.predict(X_test)\n",
        "\n",
        "# Print model accuracy\n",
        "accuracy_lasso = accuracy_score(y_test, y_pred_lasso)\n",
        "accuracy_lasso\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E2RjXgZa8Id",
        "outputId": "ae59533f-2fe4-44c5-9218-ac7480c04d84"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3: Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients.\n",
        "\n",
        "# Apply L2 regularization (Ridge)\n",
        "model_ridge = LogisticRegression(penalty='l2', solver='liblinear')\n",
        "model_ridge.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_ridge = model_ridge.predict(X_test)\n",
        "\n",
        "# Print model accuracy and coefficients\n",
        "accuracy_ridge = accuracy_score(y_test, y_pred_ridge)\n",
        "coefficients = model_ridge.coef_\n",
        "accuracy_ridge, coefficients\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3suVBn8a7_6",
        "outputId": "58d22c59-1509-4643-a06f-93a18d21a2f3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9777777777777777,\n",
              " array([[ 0.36479402,  1.35499766, -2.09628559, -0.92154751],\n",
              "        [ 0.4808915 , -1.58463288,  0.3937527 , -1.09224057],\n",
              "        [-1.5286415 , -1.43244729,  2.3048277 ,  2.08584535]]))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 4: Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet').\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Apply Elastic Net Regularization\n",
        "model_elasticnet = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\n",
        "model_elasticnet.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_en = model_elasticnet.predict(X_test)\n",
        "\n",
        "# Print model accuracy\n",
        "accuracy_en = accuracy_score(y_test, y_pred_en)\n",
        "accuracy_en\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDNP9Wf-a72y",
        "outputId": "a10596ee-b020-4343-e753-ed7bb5dda507"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 5: Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'.\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Apply Logistic Regression with One-vs-Rest strategy for multiclass classification\n",
        "model_ovr = LogisticRegression(multi_class='ovr', solver='liblinear')\n",
        "model_ovr.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_ovr = model_ovr.predict(X_test)\n",
        "\n",
        "# Print model accuracy\n",
        "accuracy_ovr = accuracy_score(y_test, y_pred_ovr)\n",
        "accuracy_ovr\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AixiK8TMa7t6",
        "outputId": "b8edd504-7131-4caf-a90c-10d8021bb69a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9777777777777777"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 6: Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy.\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
        "\n",
        "# Apply GridSearchCV\n",
        "grid_search = GridSearchCV(LogisticRegression(solver='liblinear'), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and accuracy\n",
        "best_params = grid_search.best_params_\n",
        "best_accuracy = grid_search.best_score_\n",
        "best_params, best_accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_OjJZLoa7kr",
        "outputId": "16322b32-9943-4740-c4f9-af996fa03485"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'C': 10, 'penalty': 'l2'}, np.float64(0.9523809523809523))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 7: Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy.\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Apply Stratified K-Fold Cross-Validation\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Evaluate using cross-validation\n",
        "cv_scores = cross_val_score(model, X, y, cv=skf)\n",
        "\n",
        "# Print the average accuracy\n",
        "average_accuracy = cv_scores.mean()\n",
        "average_accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcxAOU2Qa7b3",
        "outputId": "3b599a7a-9ff1-40ef-e2a6-c114f3c943fd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question: Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy.\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/synthetic_data.csv')\n",
        "\n",
        "# Split the dataset into features (X) and target (y)\n",
        "X = data.drop('Target', axis=1)\n",
        "y = data['Target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPf83909a7SO",
        "outputId": "7075b475-8597-4e0c-8ebe-6d3f00fe9dd9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.3667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 9: Write a Python program to apply Randomized SearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy.\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define the parameter distribution\n",
        "param_dist = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear', 'saga']}\n",
        "\n",
        "# Apply RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(LogisticRegression(), param_dist, cv=5)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and accuracy\n",
        "best_params_random = random_search.best_params_\n",
        "best_accuracy_random = random_search.best_score_\n",
        "best_params_random, best_accuracy_random\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdFm4xNIa7Jg",
        "outputId": "6861c275-b8d6-4110-f8c3-3f6cce9653a8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'solver': 'saga', 'penalty': 'l1', 'C': 1}, np.float64(0.9714285714285715))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 10: Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy.\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "# Apply One-vs-One strategy\n",
        "ovo_model = OneVsOneClassifier(LogisticRegression())\n",
        "ovo_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_ovo = ovo_model.predict(X_test)\n",
        "\n",
        "# Print model accuracy\n",
        "accuracy_ovo = accuracy_score(y_test, y_pred_ovo)\n",
        "accuracy_ovo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU55p9MYa7AU",
        "outputId": "c27b6b7f-5206-465e-a437-a8e0047dc53c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36666666666666664"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 11: Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification.\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model_binary = LogisticRegression(max_iter=200)\n",
        "model_binary.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_binary = model_binary.predict(X_test)\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_binary)\n",
        "\n",
        "# Visualize confusion matrix\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "_dVNaoHMa62y",
        "outputId": "7d002f0d-81a6-4c9d-b334-13def77bcec7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 12: Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score.\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model_precision = LogisticRegression(max_iter=200)\n",
        "model_precision.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_precision = model_precision.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "precision = precision_score(y_test, y_pred_precision, average='macro')\n",
        "recall = recall_score(y_test, y_pred_precision, average='macro')\n",
        "f1 = f1_score(y_test, y_pred_precision, average='macro')\n",
        "\n",
        "precision, recall, f1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urj78wzoa6ul",
        "outputId": "3ad21bea-d871-42cf-ab0a-0c9510445625"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 1.0, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 13: Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance.\n",
        "\n",
        "# Apply class weights to handle imbalanced data\n",
        "model_class_weight = LogisticRegression(class_weight='balanced', max_iter=200)\n",
        "model_class_weight.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_class_weight = model_class_weight.predict(X_test)\n",
        "\n",
        "# Print model accuracy\n",
        "accuracy_class_weight = accuracy_score(y_test, y_pred_class_weight)\n",
        "accuracy_class_weight\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aatYn3ZLa6mQ",
        "outputId": "d9e07f67-a1b2-4ac4-a07e-3385c481c795"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CSV file for question 14\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a synthetic Titanic dataset\n",
        "data = {\n",
        "    'PassengerId': np.arange(1, 101),\n",
        "    'Pclass': np.random.choice([1, 2, 3], size=100),\n",
        "    'Sex': np.random.choice(['male', 'female'], size=100),\n",
        "    'Age': np.random.randint(18, 80, size=100),\n",
        "    'SibSp': np.random.randint(0, 5, size=100),\n",
        "    'Parch': np.random.randint(0, 5, size=100),\n",
        "    'Fare': np.random.uniform(10, 500, size=100),\n",
        "    'Embarked': np.random.choice(['C', 'Q', 'S'], size=100),\n",
        "    'Survived': np.random.choice([0, 1], size=100)  # 0 = Not survived, 1 = Survived\n",
        "}\n",
        "\n",
        "# Convert to a DataFrame\n",
        "titanic_data = pd.DataFrame(data)\n",
        "\n",
        "# Save it as a CSV file\n",
        "titanic_data.to_csv('/content/titanic.csv', index=False)\n",
        "\n",
        "print(\"Synthetic Titanic dataset created successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1V7wp3Ma6dW",
        "outputId": "092440e3-ffb5-4b1f-bb56-7a8cb4d38c06"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic Titanic dataset created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question: Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load Titanic dataset\n",
        "titanic_data = pd.read_csv('/content/titanic.csv')\n",
        "\n",
        "# Handle missing values (for simplicity, we fill missing values with the mean or most frequent value)\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "titanic_data['Age'] = imputer.fit_transform(titanic_data[['Age']])\n",
        "\n",
        "# Convert categorical features to numeric (Sex, Embarked)\n",
        "titanic_data['Sex'] = titanic_data['Sex'].map({'male': 0, 'female': 1})\n",
        "titanic_data['Embarked'] = titanic_data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Split the dataset into features (X) and target (y)\n",
        "X = titanic_data.drop('Survived', axis=1)\n",
        "y = titanic_data['Survived']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axQfsQp-e7za",
        "outputId": "a46daf05-b64b-48b7-e9b3-64f667bb0816"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.4667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 15: Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling.\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Apply Standardization (Feature Scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model on scaled data\n",
        "model_scaled = LogisticRegression(max_iter=200)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the scaled test set\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "\n",
        "# Print model accuracy\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Train Logistic Regression model without scaling\n",
        "model_no_scaled = LogisticRegression(max_iter=200)\n",
        "model_no_scaled.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the non-scaled test set\n",
        "y_pred_no_scaled = model_no_scaled.predict(X_test)\n",
        "\n",
        "# Print model accuracy without scaling\n",
        "accuracy_no_scaled = accuracy_score(y_test, y_pred_no_scaled)\n",
        "\n",
        "accuracy_scaled, accuracy_no_scaled\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhJmcVkva6Tb",
        "outputId": "22e8dc9b-249e-403a-92fa-9425d9f1e490"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.36666666666666664, 0.36666666666666664)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 16: Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score.\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model_roc = LogisticRegression(max_iter=200)\n",
        "model_roc.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_roc = model_roc.predict_proba(X_test)[:, 1]  # Get probability for the positive class\n",
        "\n",
        "# Calculate ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred_roc)\n",
        "roc_auc\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnxMKlfCa6Js",
        "outputId": "5614b5dc-63ef-420d-86dc-74948a6c2450"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.2986425339366516)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 17: Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy.\n",
        "\n",
        "# Train Logistic Regression model with custom learning rate (C=0.5)\n",
        "model_custom_lr = LogisticRegression(C=0.5, max_iter=200)\n",
        "model_custom_lr.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_custom_lr = model_custom_lr.predict(X_test)\n",
        "\n",
        "# Print model accuracy\n",
        "accuracy_custom_lr = accuracy_score(y_test, y_pred_custom_lr)\n",
        "accuracy_custom_lr\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd4hjZv6a5_B",
        "outputId": "d9931ed9-2fc2-48f1-f9ba-f2b210429eb9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36666666666666664"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 18: Write a Python program to train Logistic Regression and identify important features based on model coefficients.\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model_features = LogisticRegression(max_iter=200)\n",
        "model_features.fit(X_train, y_train)\n",
        "\n",
        "# Get model coefficients\n",
        "coefficients = model_features.coef_[0]\n",
        "\n",
        "# Get feature names (if available)\n",
        "feature_names = X_train.columns\n",
        "\n",
        "# Display coefficients with corresponding feature names\n",
        "important_features = list(zip(feature_names, coefficients))\n",
        "important_features\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_YKmGmGa52b",
        "outputId": "ec4e55fc-25a1-4151-da21-78c4e7b42ec9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Feature_1', np.float64(-0.3970447822322947)),\n",
              " ('Feature_2', np.float64(0.2698618523629194)),\n",
              " ('Feature_3', np.float64(0.12803113856019388)),\n",
              " ('Feature_4', np.float64(0.18093817339021978)),\n",
              " ('Feature_5', np.float64(0.0016458710565557398))]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 19: Write a Python program to train Logistic Regression and evaluate its performance using Cohen's Kappa Score.\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model_kappa = LogisticRegression(max_iter=200)\n",
        "model_kappa.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_kappa = model_kappa.predict(X_test)\n",
        "\n",
        "# Calculate Cohen's Kappa score\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred_kappa)\n",
        "kappa_score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2NVHjoHa5tE",
        "outputId": "daca1cdb-5926-4b58-a118-11991ecc69d1"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(-0.3013698630136987)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 20: Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification.\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model_precision_recall = LogisticRegression(max_iter=200)\n",
        "model_precision_recall.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for the positive class\n",
        "y_pred_prob = model_precision_recall.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate Precision and Recall\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
        "\n",
        "# Plot Precision-Recall curve\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "2lGmjgsva5kl",
        "outputId": "5904e97a-4901-435f-a0c6-fd825c928e04"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 21: Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy.\n",
        "\n",
        "# Train Logistic Regression with different solvers\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "accuracy_results = {}\n",
        "\n",
        "for solver in solvers:\n",
        "    model_solver = LogisticRegression(solver=solver, max_iter=200)\n",
        "    model_solver.fit(X_train, y_train)\n",
        "    y_pred_solver = model_solver.predict(X_test)\n",
        "    accuracy_results[solver] = accuracy_score(y_test, y_pred_solver)\n",
        "\n",
        "accuracy_results\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XirlMa_Ka5b2",
        "outputId": "cb53dc8f-eca1-4552-8129-50c6a47fd8a5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'liblinear': 0.36666666666666664,\n",
              " 'saga': 0.36666666666666664,\n",
              " 'lbfgs': 0.36666666666666664}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 22: Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC).\n",
        "\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model_mcc = LogisticRegression(max_iter=200)\n",
        "model_mcc.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_mcc = model_mcc.predict(X_test)\n",
        "\n",
        "# Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc_score = matthews_corrcoef(y_test, y_pred_mcc)\n",
        "mcc_score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJctQ4aja5R2",
        "outputId": "232ddf44-34bc-4f58-ce7d-1bbc4ee440e4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(-0.30207927000959933)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 23: Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling.\n",
        "\n",
        "# Train Logistic Regression model on raw data\n",
        "model_raw = LogisticRegression(max_iter=200)\n",
        "model_raw.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the raw test set\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "\n",
        "# Print model accuracy on raw data\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "# Apply feature scaling (Standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model on scaled data\n",
        "model_scaled = LogisticRegression(max_iter=200)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the scaled test set\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "\n",
        "# Print model accuracy on scaled data\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "accuracy_raw, accuracy_scaled\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DwryqZ2a5IZ",
        "outputId": "5fb50251-4801-4256-9990-ef01dad3d960"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.36666666666666664, 0.36666666666666664)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 24: Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation.\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Train Logistic Regression model with cross-validation\n",
        "model_cv = LogisticRegression(max_iter=200)\n",
        "cv_scores = cross_val_score(model_cv, X_train, y_train, cv=5)\n",
        "\n",
        "# Print average cross-validation score\n",
        "cv_scores.mean()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkdTpyX3a4-e",
        "outputId": "24c25c63-d480-411e-babc-b43011ea43dc"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.5857142857142856)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 25: Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions.\n",
        "\n",
        "import joblib\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model_save = LogisticRegression(max_iter=200)\n",
        "model_save.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model using joblib\n",
        "joblib.dump(model_save, 'logistic_regression_model.pkl')\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = joblib.load('logistic_regression_model.pkl')\n",
        "\n",
        "# Predict using the loaded model\n",
        "y_pred_loaded = loaded_model.predict(X_test)\n",
        "\n",
        "# Print accuracy of the loaded model\n",
        "accuracy_loaded = accuracy_score(y_test, y_pred_loaded)\n",
        "accuracy_loaded\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uffSNJPla4l_",
        "outputId": "8ab6a564-c01d-4707-d0f1-d33724c30e9e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36666666666666664"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    }
  ]
}